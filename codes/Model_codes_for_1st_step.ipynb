{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW5GH0rvtIDd"
      },
      "source": [
        "# Model codes for 1st step of LLM-augumented Statistic Causal Discovery\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NdB8DG3Z4bi"
      },
      "source": [
        "###Installing the packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWw1GzgjQAFm",
        "outputId": "67b2f4bd-c74a-4b93-ea5b-331f84696690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.25.0 in /usr/local/lib/python3.10/dist-packages (1.25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.25.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59CJeENtDV8"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install lingam\n",
        "!pip install factor_analyzer\n",
        "!pip install igraph\n",
        "!pip install pygam\n",
        "!pip install causal-learn\n",
        "!pip install semopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1dtUs8GbDVn"
      },
      "source": [
        "### Importing and standadizing of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPc0JWSzJK9B"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('') #read the csv file of the dataset here.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR507HCyQydo"
      },
      "outputs": [],
      "source": [
        "# standardization\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df)\n",
        "X =pd.DataFrame(X,columns=df.columns)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hEsaKYnIjHk"
      },
      "source": [
        "Basic functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function for evaluating the of model fitting\n",
        "\n",
        "def evaluate_model_fit(adjacency_matrix, X, is_ordinal=None):\n",
        "    \"\"\" evaluate the given adjacency matrix and return fit indices\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    adjacency_matrix : array-like, shape (n_features, n_features)\n",
        "        Adjacency matrix representing a causal graph.\n",
        "        The i-th column and row correspond to the i-th column of X.\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training data.\n",
        "    is_ordinal : array-like, shape (n_features,)\n",
        "        Binary list. The i-th element represents that the i-th column of X is ordinal or not.\n",
        "        0 means not ordinal, otherwise ordinal.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    fit_indices : pandas.DataFrame\n",
        "        Fit indices. This API uses semopy's calc_stats(). See semopy's reference for details.\n",
        "    \"\"\"\n",
        "\n",
        "    # check inputs\n",
        "    adj = check_array(adjacency_matrix, force_all_finite=\"allow-nan\")\n",
        "    if adj.ndim != 2 or (adj.shape[0] != adj.shape[1]):\n",
        "        raise ValueError(\"adj must be an square matrix.\")\n",
        "\n",
        "    X = check_array(X)\n",
        "    if X.shape[1] != adj.shape[1]:\n",
        "        raise ValueError(\"X.shape[1] and adj.shape[1] must be the same.\")\n",
        "\n",
        "    if is_ordinal is None:\n",
        "        is_ordinal = np.zeros(X.shape[1])\n",
        "    else:\n",
        "        is_ordinal = check_array(is_ordinal, ensure_2d=False).flatten()\n",
        "    if is_ordinal.shape[0] != adj.shape[1]:\n",
        "        raise ValueError(\"is_ordinal.shape[0] and adj.shape[1] must be the same.\")\n",
        "\n",
        "    # build desc\n",
        "    desc = \"\"\n",
        "    eta_names = []\n",
        "\n",
        "    for i, row in enumerate(adj):\n",
        "        # exogenous\n",
        "        if np.sum(np.isnan(row)) == 0 and np.sum(np.isclose(row, 0)) == row.shape[0]:\n",
        "            continue\n",
        "\n",
        "        desc += f\"x{i:d} ~ \"\n",
        "\n",
        "        for j, elem in enumerate(row):\n",
        "            if np.isnan(elem):\n",
        "                eta_name = f\"eta_{i}_{j}\" if i < j else f\"eta_{j}_{i}\"\n",
        "                desc += f\"{eta_name} + \"\n",
        "                if eta_name not in eta_names:\n",
        "                    eta_names.append(eta_name)\n",
        "            elif not np.isclose(elem, 0):\n",
        "                desc += f\"x{j:d} + \"\n",
        "        desc = desc[:-len(\" * \")] + \"\\n\"\n",
        "\n",
        "    if len(eta_names) > 0:\n",
        "        desc += \"DEFINE(latent) \" + \" \".join(eta_names) + \"\\n\"\n",
        "\n",
        "    if sum(is_ordinal) > 0:\n",
        "        indices = np.argwhere(is_ordinal).flatten()\n",
        "\n",
        "        desc += \"DEFINE(ordinal)\"\n",
        "        for i in indices:\n",
        "            desc += f\" x{i}\"\n",
        "        desc += \"\\n\"\n",
        "\n",
        "    columns = [f\"x{i:d}\" for i in range(X.shape[1])]\n",
        "    X = pd.DataFrame(X, columns=columns)\n",
        "\n",
        "    m = semopy.Model(desc)\n",
        "    m.fit(X)\n",
        "\n",
        "    stats = semopy.calc_stats(m)\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "kezjC_1i9j1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjacency matrix generation from the default output of PC algorithm in causal-learn\n",
        "def create_adjacency_matrix(cg):\n",
        "\n",
        "    num_nodes = len(cg.G.nodes)\n",
        "    adj_matrix = np.zeros((num_nodes, num_nodes),dtype=int)\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "                # i <- j\n",
        "                if cg.G.graph[i][j] == 1 and cg.G.graph[j][i] == -1:\n",
        "                    adj_matrix[i, j] = 1\n",
        "                # i -- j\n",
        "                elif cg.G.graph[i][j] == -1 and cg.G.graph[j][i] == -1:\n",
        "                    adj_matrix[i, j] = -1\n",
        "                # i <->\n",
        "                elif cg.G.graph[i][j] == 1 and cg.G.graph[j][i] == 1:\n",
        "                    adj_matrix[i, j] = 2\n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "JeQrpfacqc7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for bootstrap in PC and Exact Search\n",
        "def bootstrap_PC_edge_probabilities(data, n_sampling):\n",
        "\n",
        "    num_nodes = data.shape[1]\n",
        "    directed_edge_counts = np.zeros((num_nodes, num_nodes))\n",
        "    undirected_edge_counts = np.zeros((num_nodes, num_nodes))\n",
        "    bidirected_edge_counts = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "    for _ in range(n_sampling):\n",
        "\n",
        "        bootstrap_sample = resample(data)\n",
        "        bootstrap_sample_array = bootstrap_sample.to_numpy()\n",
        "\n",
        "\n",
        "        cg = pc(bootstrap_sample_array, independence_test_method=\"fisherz\",verbose=False, show_progress=False)\n",
        "\n",
        "\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if i != j:\n",
        "                    if cg.G.graph[i][j] == 1 and cg.G.graph[j][i] == -1:  # i <- j\n",
        "                        directed_edge_counts[i, j] += 1\n",
        "                    elif cg.G.graph[i][j] == -1 and cg.G.graph[j][i] == -1:  # i -- j\n",
        "                        undirected_edge_counts[i, j] += 1\n",
        "                    elif cg.G.graph[i][j] == 1 and cg.G.graph[j][i] == 1:  # i <-> j\n",
        "                        bidirected_edge_counts[i, j] += 1\n",
        "\n",
        "\n",
        "    directed_edge_probabilities = directed_edge_counts / n_sampling\n",
        "    undirected_edge_probabilities = undirected_edge_counts / n_sampling\n",
        "    bidirected_edge_probabilities = bidirected_edge_counts / n_sampling\n",
        "\n",
        "    return directed_edge_probabilities, undirected_edge_probabilities, bidirected_edge_probabilities\n",
        "\n",
        "def bootstrap_ExactSearch_edge_probabilities(data, n_sampling,super_graph):\n",
        "\n",
        "    num_nodes = data.shape[1]\n",
        "    directed_edge_counts = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "    for _ in range(n_sampling):\n",
        "\n",
        "        bootstrap_sample = resample(data)\n",
        "        bootstrap_sample_array = bootstrap_sample.to_numpy()\n",
        "\n",
        "\n",
        "        dag_est, search_stats = bic_exact_search(bootstrap_sample_array, super_graph=super_graph,verbose=False)\n",
        "\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if i != j:\n",
        "                    if dag_est[i][j] == 1:  # i <- j\n",
        "                        directed_edge_counts[i, j] += 1\n",
        "\n",
        "    directed_edge_probabilities = directed_edge_counts / n_sampling\n",
        "\n",
        "    return directed_edge_probabilities"
      ],
      "metadata": {
        "id": "qP3oqI3AzSYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1st step (statistical causal discovery without prior knowledge)"
      ],
      "metadata": {
        "id": "aXhsdsJKt_Bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PC"
      ],
      "metadata": {
        "id": "A4IqlddWNfpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# causal discovery\n",
        "X_array = X.to_numpy()\n",
        "pcg = pc(X_array, independence_test_method=\"fisherz\")\n",
        "total_adj_matrix_pc = create_adjacency_matrix(pcg)\n",
        "np.savetxt('total_adj_matrix_pc.csv', total_adj_matrix_pc, delimiter=',')\n",
        "total_adj_matrix_pc"
      ],
      "metadata": {
        "id": "06dZgV8Vpy8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation of model fittng stats\n",
        "model_stats_pc_total = evaluate_model_fit(total_adj_matrix_pc, X)\n",
        "model_stats_pc_total.to_csv('model_stats_pc_total.csv', index=False)\n",
        "model_stats_pc_total"
      ],
      "metadata": {
        "id": "V55_8AuxyCRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bootstrap for 1000 times\n",
        "PC_directed_prob_total,PC_undirected_prob_total,PC_bidirected_prob_total = bootstrap_PC_edge_probabilities(X, n_sampling=1000)\n",
        "\n",
        "np.savetxt('PC_directed_prob_total.csv', PC_directed_prob_total, delimiter=',')\n",
        "np.savetxt('PC_undirected_prob_total.csv', PC_undirected_prob_total, delimiter=',')\n",
        "np.savetxt('PC_bidirected_prob_total.csv', PC_bidirected_prob_total, delimiter=',')\n",
        "PC_directed_prob_total,PC_undirected_prob_total,PC_bidirected_prob_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSup53431B9_",
        "outputId": "b4275f06-f5b7-4995-bb85-4723ff11ba58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.   , 0.02 , 0.362, 0.635, 0.597],\n",
              "        [0.058, 0.   , 0.108, 0.186, 0.   ],\n",
              "        [0.328, 0.615, 0.   , 0.353, 0.819],\n",
              "        [0.199, 0.433, 0.059, 0.   , 0.52 ],\n",
              "        [0.031, 0.001, 0.069, 0.068, 0.   ]]),\n",
              " array([[0.   , 0.06 , 0.273, 0.166, 0.106],\n",
              "        [0.06 , 0.   , 0.007, 0.381, 0.   ],\n",
              "        [0.273, 0.007, 0.   , 0.151, 0.112],\n",
              "        [0.166, 0.381, 0.151, 0.   , 0.108],\n",
              "        [0.106, 0.   , 0.112, 0.108, 0.   ]]),\n",
              " array([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exact Search"
      ],
      "metadata": {
        "id": "4sbhM-dmN0Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# causal discovery\n",
        "X_array = X.to_numpy()\n",
        "total_adj_matrix_ES, search_stats = bic_exact_search(X_array)\n",
        "np.savetxt('total_adj_matrix_ES.csv', total_adj_matrix_ES, delimiter=',')\n",
        "total_adj_matrix_ES"
      ],
      "metadata": {
        "id": "3QiNe8_cp371"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation of model fittng stats\n",
        "model_stats_ES_total = evaluate_model_fit(total_adj_matrix_ES, X)\n",
        "model_stats_ES_total.to_csv('model_stats_ES_total.csv', index=False)\n",
        "model_stats_ES_total"
      ],
      "metadata": {
        "id": "pkV45tTbygbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bootstrap for 1000 times\n",
        "ES_prob_total = bootstrap_ExactSearch_edge_probabilities(X, n_sampling=1000,super_graph=None)\n",
        "\n",
        "np.savetxt('ES_prob_total.csv', ES_prob_total, delimiter=',')\n",
        "ES_prob_total"
      ],
      "metadata": {
        "id": "0auSsZE24Ju-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DirectLiNGAM"
      ],
      "metadata": {
        "id": "lnZWUHv0OBW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQX2m9L0JjaR"
      },
      "outputs": [],
      "source": [
        "# causal discovery\n",
        "total_LiNGAM = lingam.DirectLiNGAM(prior_knowledge=None)\n",
        "total_LiNGAM.fit(df)\n",
        "np.savetxt('total_adj_matrix_LiNGAM.csv', total_LiNGAM.adjacency_matrix_, delimiter=',')\n",
        "total_LiNGAM.adjacency_matrix_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation of model fittng stats\n",
        "evaluate_model_fit(total_LiNGAM.adjacency_matrix_, X)"
      ],
      "metadata": {
        "id": "blh39gfCymvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bootstrap for 1000 times\n",
        "bootstrap_LiNGAM_total = total_LiNGAM.bootstrap(X, n_sampling=1000)\n",
        "LiNGAM_prob_total = bootstrap_LiNGAM_total.get_probabilities(min_causal_effect=0.01)\n",
        "np.savetxt('LiNGAM_prob_total.csv', LiNGAM_prob_total, delimiter=',')\n",
        "LiNGAM_prob_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzdlLOA76AFM",
        "outputId": "a6d4caa5-2889-40ae-fde3-7c21c22390bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.008, 0.119, 0.39 , 0.039],\n",
              "       [0.696, 0.   , 0.367, 0.593, 0.159],\n",
              "       [0.857, 0.413, 0.   , 0.596, 0.738],\n",
              "       [0.61 , 0.407, 0.366, 0.   , 0.306],\n",
              "       [0.902, 0.227, 0.262, 0.692, 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sampling of the subset(only for health screening data in our study)"
      ],
      "metadata": {
        "id": "9AVoriPk7bc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "function for sampling"
      ],
      "metadata": {
        "id": "r85dcC49R8Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling_many_patterns(data, n_samples, sampling_times):\n",
        "  sampled_dfs = []\n",
        "  #data: pandasのデータフレーム形式で。\n",
        "  #n_samples: 抽出件数\n",
        "  #sampling_times: 抽出回数\n",
        "  for m in range(sampling_times):\n",
        "    sampled_df = data.sample(n = n_samples, replace = False)\n",
        "    sampled_dfs.append(sampled_df)\n",
        "  return sampled_dfs"
      ],
      "metadata": {
        "id": "Pj8iwQST71hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#searchng the subset where x_i <--- x_j does not apprear with PC, Exact Search and DirectLiNGAM\n",
        "def search_unbelievable_sampling(i, j, data, n_samples, sampling_times,boot_number):\n",
        "  #i:index of the effected variable in  ground truth\n",
        "  #j:index of the caus variable in  ground truth\n",
        "  #data:\n",
        "  #n_samples: number of sampling\n",
        "  #sampling_times: repeating times of sampling\n",
        "  #boot_number: number of bootstrap sampling\n",
        "\n",
        "  sampled_dfs = sampling_many_patterns(data, n_samples, sampling_times)\n",
        "  for m in range(sampling_times):\n",
        "    sample_df = sampled_dfs[m]\n",
        "    scaler = StandardScaler()\n",
        "    sample_X = scaler.fit_transform(sample_df)\n",
        "    sample_X =pd.DataFrame(sample_X,columns=sample_df.columns)\n",
        "\n",
        "\n",
        "    sample_X_array = sample_X.to_numpy()\n",
        "    pcg = pc(sample_X_array, independence_test_method=\"fisherz\")\n",
        "    adj_matrix_PC = create_adjacency_matrix(pcg)\n",
        "\n",
        "    adj_matrix_ES, search_stats = bic_exact_search(sample_X_array)\n",
        "\n",
        "    LiNGAM_model = lingam.DirectLiNGAM(prior_knowledge=None)\n",
        "    LiNGAM_model.fit(sample_X)\n",
        "    adj_matrix_LiNGAM = LiNGAM_model.adjacency_matrix_\n",
        "\n",
        "    output_data = None\n",
        "\n",
        "    if (adj_matrix_PC[i,j]!=1) & (adj_matrix_ES[i,j]==0) & (adj_matrix_LiNGAM[i,j]==0):\n",
        "      output_data = sample_df\n",
        "      output_adj_PC = adj_matrix_PC\n",
        "      output_adj_ES = adj_matrix_ES\n",
        "      output_adj_LiNGAM = adj_matrix_LiNGAM\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  if output_data is None or output_data.empty:\n",
        "    return \"Error: let's try increasing n_samples\"\n",
        "  else:\n",
        "    print(\"A sub-dataset missing x_i<---x_j detected!\")\n",
        "    #bootstrap\n",
        "    PC_directed_prob,PC_undirected_prob,PC_bidirected_prob = bootstrap_PC_edge_probabilities(sample_X, n_sampling=boot_number)\n",
        "    print(\"Bootstrap in PC finished.\")\n",
        "    ES_prob_total = bootstrap_ExactSearch_edge_probabilities(sample_X, n_sampling=1000,super_graph=None)\n",
        "    print(\"Bootstrap in Exact Search finished.\")\n",
        "    bootstrap_LiNGAM = total_LiNGAM.bootstrap(sample_X, n_sampling=1000)\n",
        "    LiNGAM_prob = bootstrap_LiNGAM.get_probabilities(min_causal_effect=0.01)\n",
        "    print(\"Bootstrap in DirecLiNGAM finished.\")\n",
        "\n",
        "    model_stats_PC = evaluate_model_fit(output_adj_PC, sample_X)\n",
        "    model_stats_ES = evaluate_model_fit(output_adj_ES, sample_X)\n",
        "    model_stats_LiNGAM = evaluate_model_fit(output_adj_LiNGAM, sample_X)\n",
        "\n",
        "    return output_data, output_adj_PC, output_adj_ES,output_adj_LiNGAM, PC_directed_prob, PC_undirected_prob, PC_bidirected_prob, ES_prob_total, LiNGAM_prob, model_stats_PC, model_stats_ES, model_stats_LiNGAM"
      ],
      "metadata": {
        "id": "ShtYlxZU-ggu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "i = 1\n",
        "j = 3\n",
        "n_samples=100\n",
        "sampling_times=100\n",
        "boot_number=100\n",
        "\n",
        "sampled_X, sampled_adj_PC, sampled_adj_ES,sampled_adj_LiNGAM, PC_directed_prob_sampled, PC_undirected_prob_sampled, PC_bidirected_prob_sampled,  ES_prob_total_sampled, LiNGAM_prob_sampled, model_stats_PC_sampled, model_stats_ES_sampled, model_stats_LiNGAM_sampled = search_unbelievable_sampling(i, j, df, n_samples, sampling_times,boot_number)\n",
        "\n",
        "sampled_X.to_csv('sampled_data.csv', index=False)\n",
        "\n",
        "\n",
        "np.savetxt('sampled_adj_PC.csv', sampled_adj_PC, delimiter=',')\n",
        "np.savetxt('sampled_adj_ES.csv', sampled_adj_ES, delimiter=',')\n",
        "np.savetxt('sampled_adj_LiNGAM.csv', sampled_adj_LiNGAM, delimiter=',')\n",
        "np.savetxt('PC_directed_prob_sampled.csv', PC_directed_prob_sampled, delimiter=',')\n",
        "np.savetxt('PC_undirected_prob_sampled.csv', PC_undirected_prob_sampled, delimiter=',')\n",
        "np.savetxt('PC_bidirected_prob_sampled.csv', PC_bidirected_prob_sampled, delimiter=',')\n",
        "np.savetxt('ES_prob_total_sampled.csv', ES_prob_total_sampled, delimiter=',')\n",
        "np.savetxt('LiNGAM_prob_sampled.csv', LiNGAM_prob_sampled, delimiter=',')\n",
        "\n",
        "model_stats_PC_sampled.to_csv('model_stats_PC_sampled.csv', index=False)\n",
        "model_stats_ES_sampled.to_csv('model_stats_ES_sampled.csv', index=False)\n",
        "model_stats_LiNGAM_sampled.to_csv('model_stats_LiNGAM_sampled.csv', index=False)"
      ],
      "metadata": {
        "id": "Yfo9DuxUJGCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_X"
      ],
      "metadata": {
        "id": "34UeTWGlJkoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_adj_PC"
      ],
      "metadata": {
        "id": "mGDxoaW6LJpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_adj_ES"
      ],
      "metadata": {
        "id": "Vwz7AeMELNmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_adj_LiNGAM"
      ],
      "metadata": {
        "id": "hqwb9_weLPPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PC_directed_prob_sampled"
      ],
      "metadata": {
        "id": "N-DFrJd4LSHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PC_undirected_prob_sampled"
      ],
      "metadata": {
        "id": "GYU7ey87RqOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ES_prob_total_sampled"
      ],
      "metadata": {
        "id": "5A6ylRgLLXx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LiNGAM_prob_sampled"
      ],
      "metadata": {
        "id": "U_aFsfnYLZ4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_stats_PC_sampled"
      ],
      "metadata": {
        "id": "wrXFdFXXLceQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_stats_ES_sampled"
      ],
      "metadata": {
        "id": "6rVRuspPO5r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_stats_LiNGAM_sampled"
      ],
      "metadata": {
        "id": "nkhr5kBQO8cj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}